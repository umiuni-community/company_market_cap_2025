{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Function to format market cap\n",
    "def format_market_cap(value):\n",
    "    \"\"\"\n",
    "    Convert market cap strings like '1.5T' and '500B' into numerical values.\n",
    "    \"\"\"\n",
    "    multipliers = {'T': 1e12, 'B': 1e9, 'M': 1e6}\n",
    "    if value[-1] in multipliers:\n",
    "        return float(value[:-1]) * multipliers[value[-1]]\n",
    "    return float(value.replace(',', ''))\n",
    "\n",
    "# Function to scrape and clean market cap data\n",
    "def scrape_market_cap(company_symbol):\n",
    "    base_url = \"https://www.marketcaphistory.com/\"\n",
    "    search_url = base_url + company_symbol.lower()\n",
    "    \n",
    "    try:\n",
    "        # Fetch the webpage\n",
    "        response = requests.get(search_url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Parse the webpage\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        # Extract market cap data\n",
    "        outer_table = soup.find('table', class_='infotable')\n",
    "        inner_table = outer_table.find('table')\n",
    "        rows = inner_table.find_all('tr')\n",
    "\n",
    "        market_cap_data = []\n",
    "    \n",
    "        for index, row in enumerate(rows):\n",
    "            if index == 0:  # Skip the header row\n",
    "                continue\n",
    "\n",
    "            cells = row.find_all('td')\n",
    "            if cells:\n",
    "                date = pd.to_datetime(cells[0].get_text(strip=True)).strftime('%Y-%m-%d')  # Convert to YYYY-MM-DD\n",
    "                market_cap = format_market_cap(cells[1].get_text(strip=True))  # Convert to number\n",
    "\n",
    "                market_cap_data.append([company_symbol.upper(), date, market_cap])\n",
    "        \n",
    "        print(f\"Got {company_symbol} data\")\n",
    "\n",
    "        # Create a DataFrame \n",
    "        df = pd.DataFrame(market_cap_data, columns=[\"Company\", \"Date\", \"Market Cap\"])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping data for {company_symbol}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got CMAX data\n",
      "   Company        Date   Market Cap\n",
      "0     CMAX  2021-05-17  181560000.0\n",
      "1     CMAX  2021-08-12  679890000.0\n",
      "2     CMAX  2022-03-11  680600000.0\n",
      "3     CMAX  2022-04-29  575750000.0\n",
      "4     CMAX  2022-08-05  631880000.0\n",
      "5     CMAX  2022-11-07  514770000.0\n",
      "6     CMAX  2023-03-11  262980000.0\n",
      "7     CMAX  2023-03-22  344100000.0\n",
      "8     CMAX  2023-08-04  303730000.0\n",
      "9     CMAX  2023-11-06  210740000.0\n",
      "10    CMAX  2024-05-06   11750000.0\n",
      "11    CMAX  2024-08-06   17630000.0\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "df = scrape_market_cap(\"CMAX\")\n",
    "print(df)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"CMAX.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for AAPL...\n",
      "Got AAPL data\n",
      "Data saved to data/AAPL_market_cap.csv\n",
      "Scraping data for GOOG...\n",
      "Got GOOG data\n",
      "Data saved to data/GOOG_market_cap.csv\n",
      "Scraping data for MSFT...\n",
      "Got MSFT data\n",
      "Data saved to data/MSFT_market_cap.csv\n",
      "Scraping data for AMZN...\n",
      "Got AMZN data\n",
      "Data saved to data/AMZN_market_cap.csv\n",
      "Scraping data for TSLA...\n",
      "Got TSLA data\n",
      "Data saved to data/TSLA_market_cap.csv\n"
     ]
    }
   ],
   "source": [
    "# List of company symbols to scrape\n",
    "company_symbols = ['AAPL', 'GOOG', 'MSFT', 'AMZN', 'TSLA']\n",
    "\n",
    "# Loop through each company symbol and scrape data\n",
    "for company_symbol in company_symbols:\n",
    "    print(f\"Scraping data for {company_symbol}...\")\n",
    "    company_df = scrape_market_cap(company_symbol)\n",
    "\n",
    "    if not company_df.empty:  # Only save if data is retrieved successfully\n",
    "        company_df[\"Company\"] = company_symbol  # Add the company symbol\n",
    "        filename = f\"data/{company_symbol}_market_cap.csv\"\n",
    "        company_df.to_csv(filename, index=False)\n",
    "        print(f\"Data saved to {filename}\")\n",
    "\n",
    "    # time.sleep(1)  # Delay to prevent overwhelming the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umiuni_stock_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
